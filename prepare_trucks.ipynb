{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Trucks detection with COLAB and Neptune\n",
    "\n",
    "trying to follow https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api with my data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-s3-luk/avocado/labels_avocadoproject_2021-10-10-09-33-06.zip to images/labels_avocadoproject_2021-10-10-09-33-06.zip\n",
      "download: s3://sagemaker-s3-luk/avocado/iCloud Photos (5).zip to images/iCloud Photos (5).zip\n"
     ]
    }
   ],
   "source": [
    "! aws s3 sync s3://sagemaker-s3-luk/avocado/ images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations\n",
      "avocadoproject\n",
      "iCloud Photos\n",
      "iCloud Photos (5).zip\n",
      "img_and_annotations\n",
      "labels_avocadoproject_2021-10-10-09-33-06.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd images\n",
    "rm -rf 'iCloud Photos'\n",
    "unzip -q 'iCloud Photos (5).zip'\n",
    "rm -rf annotations\n",
    "unzip -q labels_avocadoproject_2021-10-10-09-33-06.zip -d annotations\n",
    "rm -rf avocadoproject\n",
    "mkdir avocadoproject\n",
    "mv annotations/* avocadoproject\n",
    "mv 'iCloud Photos'/* avocadoproject\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -r images/img_and_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oi28cqGGFWnY",
    "outputId": "f92ca728-6a86-43ab-ac10-873c131bf207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 2935, done.\u001b[K\n",
      "remote: Counting objects: 100% (2935/2935), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2472/2472), done.\u001b[K\n",
      "remote: Total 2935 (delta 744), reused 1257 (delta 426), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2935/2935), 33.02 MiB | 15.72 MiB/s, done.\n",
      "Resolving deltas: 100% (744/744), done.\n"
     ]
    }
   ],
   "source": [
    "# already done while creating a notebook\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/models/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NwdsBdGhFanc"
   },
   "outputs": [],
   "source": [
    "# TODO: do it if not already prepared..\n",
    "! protoc object_detection/protos/*.proto --python_out=/home/ec2-user/SageMaker/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ec2-user/SageMaker/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.33.0-cp36-cp36m-manylinux2010_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (8.3.2)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: Cython in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (0.29.22)\n",
      "Requirement already satisfied: contextlib2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (0.6.0.post1)\n",
      "Collecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (1.15.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (1.5.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from object-detection==0.1) (1.1.5)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 57.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.15.2)\n",
      "Collecting orjson<4.0; python_version >= \"3.6\"\n",
      "  Downloading orjson-3.6.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 66.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2.26.0)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.8)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (523 kB)\n",
      "\u001b[K     |████████████████████████████████| 523 kB 54.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 846 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<5.0.0,>=0.15.1\n",
      "  Downloading pyarrow-4.0.1-cp36-cp36m-manylinux2014_x86_64.whl (21.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.9 MB 51.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 71.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2,>=1.29.0\n",
      "  Downloading grpcio-1.41.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 56.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.10.0.2)\n",
      "Collecting oauth2client<5,>=2.0.1\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future<1.0.0,>=0.18.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Collecting absl-py>=0.2.2\n",
      "  Downloading absl_py-0.14.1-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 69.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pycocotools->object-detection==0.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from lvis->object-detection==0.1) (4.5.1.48)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-text>=2.5.0\n",
      "  Downloading tensorflow_text-2.6.0-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 56.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.8.0)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp36-cp36m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 43.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.27.0-py2.py3-none-any.whl (7.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.7 MB 30.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.2 MB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.5.0\n",
      "  Downloading tensorflow-2.6.0-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 16 kB/s s eta 0:00:01     |███████████████████████████████ | 443.3 MB 73.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 68.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 68.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 47.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.14.0-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 42.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.6)\n",
      "Requirement already satisfied: docopt in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 74.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.2)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.0\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-2.1.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Downloading google_auth-2.3.0-py2.py3-none-any.whl (154 kB)\n",
      "\u001b[K     |████████████████████████████████| 154 kB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2020.11.13)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 36.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.36.2)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 46.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.6-cp36-cp36m-manylinux2014_x86_64.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 31.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (20.3.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.3.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.24.1)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.0-py3-none-any.whl (17 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 65.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 781 kB 48.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 71.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 72.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: object-detection, avro-python3, pycocotools, dill, crcmod, kaggle, py-cpuinfo, seqeval, clang, termcolor, promise\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1668658 sha256=1d5a66f0e5b9faccac66f608eedb7ef66667814333641db99a274ba2d70a48ef\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k8ya_q1m/wheels/0f/f9/3c/80b1718c9d2eb5b6a4cae1495bfab9871f89c411c41b586424\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=b680e97dbd5918ad41c78551f337183fbcc5e396f5829c70c05421feace52683\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5b/6f/ca/80164a844e4691238e34a8b139b4695354df4490db91be61f7\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl size=301742 sha256=239fa514dc0fcc00addb7700bda0a7d174f8f0e8340c90797102fd35a40e9003\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d8/c2/ba/8f5306f921c2e79ad7b09effdfed6bd966cfcf8c6fe55422d6\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78532 sha256=a73793225fb1dbe0f45eac1bf7ef47ae8eb0d0914383d0ed50118318a2d4e80b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp36-cp36m-linux_x86_64.whl size=30488 sha256=1d6dc8364439fafb1856e540e33c1f9b58bea7b1e783f4ef4d6a334d7cd9a6fb\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ac/bb/07/adfb4ffd0aaace2022ea25c082a7cdc688b10d30e86d6d2fde\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=fcc39b4cb69c553ad32f553dcc96bee7eaf09e82b15f4cb18e0ed8a14f3841cb\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/77/47/e4/44a4ba1b7dfd53faaa35f59f1175e123b213ff401a8a56876b\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22245 sha256=43d545b8c497d891d7ca52f2339a63cc4089c3b246c54e4a4b776f036baa0456\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/3e/e1/d9/9b782b170e5272d6500cee4d29dd6c724598b22dc399d81d01\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=5c3101fbaf7a8f3cdef2ba9cdfa9657993af8bef5bbed7644bfbd95adc4410bc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/39/29/36/1c4f7905c133e11748ca375960154964082d4fb03478323089\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=099916d732c34acad17b4b187ba14fcab67f8703171aa01a7bd6b1c675afddfc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=69c0be2b14a7dad9fb3a14ac5daefe2c0f382ae5f98393b678e72ce7d698ef9e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=fc1b4aa00e7c6e6e8bcf89c1238a026f4b6e7012ec16922d0584df5f3a92daf5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "Successfully built object-detection avro-python3 pycocotools dill crcmod kaggle py-cpuinfo seqeval clang termcolor promise\n",
      "Installing collected packages: avro-python3, orjson, fastavro, pymongo, hdfs, httplib2, pyarrow, dill, grpcio, pyasn1-modules, oauth2client, pydot, crcmod, apache-beam, absl-py, tf-slim, pycocotools, lvis, text-unidecode, python-slugify, kaggle, opt-einsum, keras, clang, keras-preprocessing, termcolor, astunparse, gast, tensorflow-estimator, markdown, cachetools, google-auth, tensorboard-plugin-wit, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, flatbuffers, tensorflow, tensorflow-hub, tensorflow-text, py-cpuinfo, opencv-python-headless, uritemplate, googleapis-common-protos, google-api-core, google-auth-httplib2, google-api-python-client, gin-config, sentencepiece, portalocker, sacrebleu, dm-tree, tensorflow-model-optimization, promise, tensorflow-metadata, importlib-resources, tensorflow-datasets, seqeval, typeguard, tensorflow-addons, tf-models-official, object-detection\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 5.0.0\n",
      "    Uninstalling pyarrow-5.0.0:\n",
      "      Successfully uninstalled pyarrow-5.0.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.2.8 requires dill>=0.3.4, but you'll have dill 0.3.1.1 which is incompatible.\n",
      "multiprocess 0.70.12.2 requires dill>=0.3.4, but you'll have dill 0.3.1.1 which is incompatible.\n",
      "apache-beam 2.33.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you'll have typing-extensions 3.10.0.2 which is incompatible.\n",
      "tensorflow-metadata 1.2.0 requires absl-py<0.13,>=0.9, but you'll have absl-py 0.14.1 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.14.1 apache-beam-2.33.0 astunparse-1.6.3 avro-python3-1.10.2 cachetools-4.2.4 clang-5.0 crcmod-1.7 dill-0.3.1.1 dm-tree-0.1.6 fastavro-1.4.5 flatbuffers-1.12 gast-0.4.0 gin-config-0.4.0 google-api-core-2.1.1 google-api-python-client-2.27.0 google-auth-2.3.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 googleapis-common-protos-1.53.0 grpcio-1.41.0 hdfs-2.6.0 httplib2-0.19.1 importlib-resources-5.3.0 kaggle-1.5.12 keras-2.6.0 keras-preprocessing-1.1.2 lvis-0.5.3 markdown-3.3.4 oauth2client-4.1.3 oauthlib-3.1.1 object-detection-0.1 opencv-python-headless-4.5.3.56 opt-einsum-3.3.0 orjson-3.6.1 portalocker-2.3.2 promise-2.3 py-cpuinfo-8.0.0 pyarrow-4.0.1 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pymongo-3.12.0 python-slugify-5.0.2 requests-oauthlib-1.3.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-addons-0.14.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.2.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.6.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.6.0 tf-slim-1.1.0 typeguard-2.13.0 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --use-deprecated=legacy-resolver . \n",
    "# !python -m pip install --use-feature=2020-resolver ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uZcqD4NLdnf4"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from lxml import etree\n",
    "import PIL.Image\n",
    "import tensorflow.compat.v1 as compat_tf\n",
    "import hashlib\n",
    "\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IogyryF2lFBL"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSaXL28TZfk1"
   },
   "source": [
    "# Avocado dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove orphans jpegs which does not have xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm images/avocadoproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm \"images/avocadoproject/IMG_1078.JPEG\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for filename in images/avocadoproject/*.xml\n",
    "do\n",
    "    sed -i 's/Unspecified/0/g' $filename\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ynpUpF9vcPWY"
   },
   "outputs": [],
   "source": [
    "IMAGES_AND_LABELS_FOLDER = \"images/avocadoproject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8FHRkY_Qx_p",
    "outputId": "be473726-0ede-4836-ec6b-80fca75399e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 119 elements, valid 14, test 16\n",
      "['IMG_1218.JPEG', 'IMG_1109.JPEG', 'IMG_1108.JPEG', 'IMG_1189.JPEG', 'IMG_1209.JPEG'] ['IMG_1133.JPEG', 'IMG_1111.JPEG', 'IMG_1081.JPEG', 'IMG_1110.JPEG', 'IMG_1096.JPEG']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "def train_valid_test_split(path, split_ratio=(0.8,0.1,0.1)):\n",
    "  all_images = list(os.path.basename(filename) for filename in glob.glob(os.path.join(path, \"*.JPEG\")))\n",
    "  if len(split_ratio) != 3:\n",
    "    raise AttributeError(\"you should provide a tuple with 3 fractions for split- train,valid,test\")\n",
    "  if sum(split_ratio) != 1:\n",
    "    raise AttributeError(\"Split should add up to 1.0\")\n",
    "  train_len = math.floor(split_ratio[0] * len(all_images))\n",
    "  random.seed(10)\n",
    "  train_images = random.sample(all_images, train_len)\n",
    "  other_images = list(set(all_images) - set(train_images))\n",
    "  valid_len = math.floor(split_ratio[1] * len(all_images))\n",
    "  valid_images = random.sample(other_images, valid_len)\n",
    "  test_images = list(set(other_images) - set(valid_images))\n",
    "  return train_images, valid_images, test_images\n",
    "\n",
    "train_images, valid_images, test_images = train_valid_test_split(IMAGES_AND_LABELS_FOLDER)\n",
    "\n",
    "print(\"train has %d elements, valid %d, test %d\" % (len(train_images), len(valid_images), len(test_images)))\n",
    "print(train_images[:5], valid_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_1096.JPEG', 'IMG_1196.JPEG', 'IMG_1165.JPEG', 'IMG_1218.JPEG', 'IMG_1116.JPEG', 'IMG_1179.JPEG', 'IMG_1210.JPEG', 'IMG_1085.JPEG', 'IMG_1101.JPEG', 'IMG_1208.JPEG', 'IMG_1182.JPEG', 'IMG_1078.JPEG', 'IMG_1123.JPEG', 'IMG_1113.JPEG', 'IMG_1192.JPEG']\n"
     ]
    }
   ],
   "source": [
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images/test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'images/avocadoproject/'\n",
    "dest_folder = 'images/test_images/'\n",
    "\n",
    "import shutil\n",
    "\n",
    "for test_image in test_images:\n",
    "    shutil.copy(source_folder + test_image, dest_folder + test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_1085.JPEG  IMG_1132.JPEG  IMG_1165.JPEG  IMG_1210.JPEG\r\n",
      "IMG_1088.JPEG  IMG_1137.JPEG  IMG_1167.JPEG  IMG_1220.JPEG\r\n",
      "IMG_1114.JPEG  IMG_1150.JPEG  IMG_1182.JPEG  IMG_1223.JPEG\r\n",
      "IMG_1130.JPEG  IMG_1161.JPEG  IMG_1206.JPEG  IMG_1224.JPEG\r\n"
     ]
    }
   ],
   "source": [
    "%ls images/test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suy4LU1LTUW7"
   },
   "source": [
    "## Create TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"item {\\\n",
    "  id: 1\\\n",
    "  name: 'avocado'\\\n",
    "}\" > /tmp/avocado_labels.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avocado': 1}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_path = \"/tmp/avocado_labels.pbtxt\"\n",
    "label_map_util.get_label_map_dict(label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zF_2IKysTThx",
    "outputId": "8322ca3f-d8aa-4b79-b1f6-011fe07ed4bd"
   },
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pascal_tf_record.py \n",
    "# customized for my needs\n",
    "\n",
    "annotations_dir = IMAGES_AND_LABELS_FOLDER\n",
    "data_dir = \"images\"\n",
    "tf_record_folder = \"./tfrecord\"\n",
    "if not os.path.exists(tf_record_folder):\n",
    "  os.mkdir(tf_record_folder)\n",
    "\n",
    "\n",
    "\n",
    "def dict_to_tf_example(data,\n",
    "                       dataset_directory,\n",
    "                       label_map_dict,\n",
    "                       ignore_difficult_instances=False):\n",
    "  \"\"\"Convert XML derived dict to tf.Example proto.\n",
    "  Notice that this function normalizes the bounding box coordinates provided\n",
    "  by the raw data.\n",
    "  Args:\n",
    "    data: dict holding PASCAL XML fields for a single image (obtained by\n",
    "      running dataset_util.recursive_parse_xml_to_dict)\n",
    "    dataset_directory: Path to root directory holding PASCAL dataset\n",
    "    label_map_dict: A map from string label names to integers ids.\n",
    "    ignore_difficult_instances: Whether to skip difficult instances in the\n",
    "      dataset  (default: False).\n",
    "    image_subdirectory: String specifying subdirectory within the\n",
    "      PASCAL dataset directory holding the actual image data.\n",
    "  Returns:\n",
    "    example: The converted tf.Example.\n",
    "  Raises:\n",
    "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "  \"\"\"\n",
    "  img_path = os.path.join(data['folder'], data['filename'])\n",
    "  full_path = os.path.join(dataset_directory, img_path)\n",
    "  with compat_tf.gfile.GFile(full_path, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "  image = PIL.Image.open(encoded_jpg_io)\n",
    "  if image.format != 'JPEG':\n",
    "    raise ValueError('Image format not JPEG')\n",
    "  key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "  width = int(data['size']['width'])\n",
    "  height = int(data['size']['height'])\n",
    "\n",
    "  xmin = []\n",
    "  ymin = []\n",
    "  xmax = []\n",
    "  ymax = []\n",
    "  classes = []\n",
    "  classes_text = []\n",
    "  truncated = []\n",
    "  poses = []\n",
    "  difficult_obj = []\n",
    "  if 'object' in data:\n",
    "    for obj in data['object']:\n",
    "      difficult = bool(int(obj['difficult']))\n",
    "      if ignore_difficult_instances and difficult:\n",
    "        continue\n",
    "\n",
    "      difficult_obj.append(int(difficult))\n",
    "\n",
    "      xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "      ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "      xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "      ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "      classes_text.append(obj['name'].encode('utf8'))\n",
    "      classes.append(label_map_dict[obj['name']])\n",
    "      truncated.append(int(obj['truncated']))\n",
    "      poses.append(obj['pose'].encode('utf8'))\n",
    "\n",
    "  example = compat_tf.train.Example(features=compat_tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data['filename'].encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }))\n",
    "  return example\n",
    "\n",
    "\n",
    "\n",
    "def files_to_tfrecord(filenames, data_dir, output_path, ignore_difficult_instances=False):\n",
    "  filenames_no_extensions = [os.path.splitext(fn)[0] for fn in filenames]\n",
    "  label_map_dict = label_map_util.get_label_map_dict(label_map_path)\n",
    "  examples = []\n",
    "  with compat_tf.python_io.TFRecordWriter(output_path) as writer:\n",
    "    for idx, example in enumerate(filenames_no_extensions):\n",
    "      path = os.path.join(annotations_dir, example + '.xml')\n",
    "      with compat_tf.gfile.GFile(path, 'r') as fid:\n",
    "        xml_str = fid.read()    \n",
    "      xml = etree.fromstring(xml_str)\n",
    "      data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    "      tf_example = dict_to_tf_example(data, data_dir, label_map_dict,\n",
    "                                      ignore_difficult_instances)\n",
    "#       print(tf_example)\n",
    "#       break\n",
    "      examples.append(tf_example)\n",
    "      writer.write(tf_example.SerializeToString())\n",
    "  # return examples\n",
    "\n",
    "files_to_tfrecord(train_images, data_dir, os.path.join(tf_record_folder, 'train'))\n",
    "files_to_tfrecord(valid_images, data_dir, os.path.join(tf_record_folder, 'valid'))\n",
    "files_to_tfrecord(test_images, data_dir, os.path.join(tf_record_folder, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avocado': 1}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_util.get_label_map_dict(label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /tmp/avocado_labels.pbtxt ./tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync ./tfrecord s3://sagemaker-s3-luk/trucks_tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pretrained_models/ssd_inception_v2_coco_2018_01_28/pipeline.docker.confignew'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_name = \"efficientdet_d1_coco17_tpu-32\"\n",
    "# model_name = \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\"\n",
    "# model_name = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "# model_name = \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\"\n",
    "# model_name= \"ssd_mobilenet_v2_320x320_coco17_tpu-8\"\n",
    "# model_name = \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\"\n",
    "model_name = \"ssd_inception_v2_coco_2018_01_28\"\n",
    "\n",
    "original_pipeline_path = f\"pretrained_models/{model_name}/pipeline.config\"\n",
    "pipeline_path = f\"pretrained_models/{model_name}/pipeline.docker.confignew\"\n",
    "# checkpoint_path = f\"workspace/pre_trained_models/{model_name}/checkpoint/ckpt-0\"\n",
    "checkpoint_path = \"checkpoint/ckpt-0\"\n",
    "# checkpoint_path = \"/content/workspace/model_customized/saved_checkpoint/ckpt-4\"\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2\n",
    "\n",
    "docker_data_folder = \"/opt/ml/input/data/train/\"\n",
    "docker_map_path = docker_data_folder + \"avocado_labels.pbtxt\"\n",
    "\n",
    "\n",
    "def edit_pipeline_config(old_path, new_path, cfg):\n",
    "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
    "\n",
    "  with compat_tf.gfile.GFile(old_path, \"r\") as f:                                                                                                                                                                                                                     \n",
    "      proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "      text_format.Merge(proto_str, pipeline_config)                                                                                                                                                                                                                 \n",
    "\n",
    "  pipeline_config.model.ssd.num_classes = cfg['num_classes']\n",
    "  pipeline_config.train_config.batch_size = cfg['batch_size']\n",
    "  pipeline_config.train_config.fine_tune_checkpoint = cfg['fine_tune_checkpoint']\n",
    "  pipeline_config.train_config.fine_tune_checkpoint_type = 'detection'\n",
    "  pipeline_config.train_input_reader.label_map_path = cfg['label_map_path']\n",
    "  pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = cfg['train_tf_path']\n",
    "  pipeline_config.eval_input_reader[0].label_map_path = cfg['label_map_path']\n",
    "  pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = cfg['eval_tf_path']\n",
    "  # print(pipeline_config)\n",
    "\n",
    "\n",
    "  config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "  with compat_tf.gfile.Open(new_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "      f.write(config_text)                                                                                                                                                                                                                                          \n",
    "\n",
    "new_config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"num_classes\": 1,\n",
    "    \"label_map_path\": docker_map_path,\n",
    "    \"train_tf_path\": os.path.join(docker_data_folder, 'train'),\n",
    "    \"eval_tf_path\": os.path.join(docker_data_folder, 'valid'),\n",
    "    \"fine_tune_checkpoint\": checkpoint_path\n",
    "}\n",
    "\n",
    "edit_pipeline_config(original_pipeline_path, pipeline_path, new_config)\n",
    "\n",
    "pipeline_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\r\n",
      "  ssd {\r\n",
      "    num_classes: 1\r\n",
      "    image_resizer {\r\n",
      "      fixed_shape_resizer {\r\n",
      "        height: 300\r\n",
      "        width: 300\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: \"ssd_inception_v2\"\r\n",
      "      depth_multiplier: 1.0\r\n",
      "      min_depth: 16\r\n",
      "      conv_hyperparams {\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 4e-05\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            mean: 0.0\r\n",
      "            stddev: 0.03\r\n",
      "          }\r\n",
      "        }\r\n",
      "        activation: RELU_6\r\n",
      "        batch_norm {\r\n",
      "          decay: 0.9997\r\n",
      "          center: true\r\n",
      "          scale: true\r\n",
      "          epsilon: 0.001\r\n",
      "          train: true\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 10.0\r\n",
      "        x_scale: 10.0\r\n",
      "        height_scale: 5.0\r\n",
      "        width_scale: 5.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      convolutional_box_predictor {\r\n",
      "        conv_hyperparams {\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 4e-05\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            truncated_normal_initializer {\r\n",
      "              mean: 0.0\r\n",
      "              stddev: 0.03\r\n",
      "            }\r\n",
      "          }\r\n",
      "          activation: RELU_6\r\n",
      "        }\r\n",
      "        min_depth: 0\r\n",
      "        max_depth: 0\r\n",
      "        num_layers_before_predictor: 0\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 0.8\r\n",
      "        kernel_size: 3\r\n",
      "        box_code_size: 4\r\n",
      "        apply_sigmoid_to_scores: false\r\n",
      "      }\r\n",
      "    }\r\n",
      "    anchor_generator {\r\n",
      "      ssd_anchor_generator {\r\n",
      "        num_layers: 6\r\n",
      "        min_scale: 0.2\r\n",
      "        max_scale: 0.95\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        aspect_ratios: 3.0\r\n",
      "        aspect_ratios: 0.3333\r\n",
      "        reduce_boxes_in_lowest_layer: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 0.3\r\n",
      "        iou_threshold: 0.6\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    loss {\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      hard_example_miner {\r\n",
      "        num_hard_examples: 3000\r\n",
      "        iou_threshold: 0.99\r\n",
      "        loss_type: CLASSIFICATION\r\n",
      "        max_negatives_per_positive: 3\r\n",
      "        min_negatives_per_image: 0\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "train_config {\r\n",
      "  batch_size: 8\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  data_augmentation_options {\r\n",
      "    ssd_random_crop {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  optimizer {\r\n",
      "    rms_prop_optimizer {\r\n",
      "      learning_rate {\r\n",
      "        exponential_decay_learning_rate {\r\n",
      "          initial_learning_rate: 0.004\r\n",
      "          decay_steps: 800720\r\n",
      "          decay_factor: 0.95\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "      decay: 0.9\r\n",
      "      epsilon: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  fine_tune_checkpoint: \"checkpoint/ckpt-0\"\r\n",
      "  from_detection_checkpoint: true\r\n",
      "  num_steps: 200000\r\n",
      "  fine_tune_checkpoint_type: \"detection\"\r\n",
      "}\r\n",
      "train_input_reader {\r\n",
      "  label_map_path: \"/opt/ml/input/data/train/avocado_labels.pbtxt\"\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/opt/ml/input/data/train/train\"\r\n",
      "  }\r\n",
      "}\r\n",
      "eval_config {\r\n",
      "  num_examples: 8000\r\n",
      "  max_evals: 10\r\n",
      "  use_moving_averages: false\r\n",
      "}\r\n",
      "eval_input_reader {\r\n",
      "  label_map_path: \"/opt/ml/input/data/train/avocado_labels.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/opt/ml/input/data/train/valid\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! cat 'pretrained_models/ssd_inception_v2_coco_2018_01_28/pipeline.docker.confignew'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trucks Object Detecion Done Right with neptune.ai",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
